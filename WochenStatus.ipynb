{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b36cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4cfd445",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogfileText = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265efb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'Suedlink_MWuB_GWAnalytik.csv' in os.listdir(\"I:/ATIBK_Projects/R794/5_WS/58_GEOL/LA225_Monitoring_Phase_1_2/_WWBS_LA225/_mDB_VHT/Export_geodin-SQL/automatisch\"):\n",
    "        geodinExportFilePath = \"I:/ATIBK_Projects/R794/5_WS/58_GEOL/LA225_Monitoring_Phase_1_2/_WWBS_LA225/_mDB_VHT/Export_geodin-SQL/automatisch/Suedlink_MWuB_GWAnalytik.csv\"\n",
    "except:\n",
    "    LogfileText = LogfileText+\"\\nKann den automatischen GeoDin Export nicht finden oder nicht darauf zugreifen unter\\nI:/ATIBK_Projects/R794/5_WS/58_GEOL/LA225_Monitoring_Phase_1_2/_WWBS_LA225/_mDB_VHT/Export_geodin-SQL/automatisch/Suedlink_MWuB_GWAnalytik.csv\\nVerwende stattdessen Datei im selben Verzeichnis wie in diesem Skript.\\n\"\n",
    "    try:\n",
    "        if 'Suedlink_MWuB_GWAnalytik.csv' in os.listdir(\".\"):\n",
    "            geodinExportFilePath = \"Suedlink_MWuB_GWAnalytik.csv\"\n",
    "        else:\n",
    "            LogfileText = LogfileText+\"\\nKann Suedlink_MWuB_GWAnalytik.csv auch im selben Verzeichnis nicht finden (/nicht darauf zugreifen)\\n\"\n",
    "    except:\n",
    "        LogfileText = LogfileText+\"\\nFehler im Abruf von Suedlink_MWuB_GWAnalytik.csv\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5964fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    ### IMPORT Aller Daten aus geodin für Statistik\n",
    "\n",
    "    with open(geodinExportFilePath, 'r') as file:\n",
    "        # Read all lines from the file\n",
    "        lines = file.readlines()\n",
    "\n",
    "        PRJ_ID = []\n",
    "        LONGNAME = []\n",
    "        SMPNAME = []\n",
    "        SMPDATE = []\n",
    "        SMPTIME = []\n",
    "        ABSTICH = []\n",
    "        TWA = []\n",
    "        EC = []\n",
    "        PH_FIELD = []\n",
    "        O2 = []\n",
    "        TURB = []\n",
    "        Sonstiges = []\n",
    "\n",
    "\n",
    "\n",
    "        # Process each line\n",
    "        for line in lines:\n",
    "            # Split the line into fields using comma as the separator\n",
    "            fields = line.strip().split(';')\n",
    "            PRJ_ID.append(fields[0])\n",
    "            LONGNAME.append(fields[1])\n",
    "            SMPNAME.append(fields[2])\n",
    "            SMPDATE.append(fields[3])\n",
    "            SMPTIME.append(fields[4])\n",
    "            try:\n",
    "                ABSTICH.append(float(fields[5]))\n",
    "            except:\n",
    "                ABSTICH.append(np.nan)\n",
    "            try:\n",
    "                TWA.append(float(fields[6]))\n",
    "            except:\n",
    "                TWA.append(np.nan)\n",
    "            try:\n",
    "                EC.append(float(fields[7].replace(\",\",\"\")))\n",
    "            except:\n",
    "                EC.append(np.nan)\n",
    "            try:\n",
    "                PH_FIELD.append(float(fields[8]))\n",
    "            except:\n",
    "                PH_FIELD.append(np.nan)\n",
    "            try:\n",
    "                O2.append(float(fields[9]))\n",
    "            except:\n",
    "                O2.append(np.nan)\n",
    "            TURB.append(fields[10])\n",
    "            Sonstiges.append(fields[11:])\n",
    "            if len(fields[11:])!= 4:\n",
    "                print(fields[11:])\n",
    "                LogfileText = LogfileText+\"\\nFehler in der Anzahl der Spalten. Überprüfe Eintrag zu \",fields[1],\" am \",fields[3],fields[4],\"\\nEs dürfen keine \\\";\\\" im frei Text verwendet werden!!\"\n",
    "\n",
    "    gd_PRJ_ID = np.array(PRJ_ID)\n",
    "    gd_LONGNAME = np.array(LONGNAME) #use this! not SMPNAME\n",
    "    gd_SMPNAME = np.array(SMPNAME) #dont use this - teilweise AUH IDs\n",
    "    gd_SMPDATE = np.array(SMPDATE)\n",
    "    gd_SMPTIME = np.array(SMPTIME)\n",
    "    gd_ABSTICH = np.array(ABSTICH)\n",
    "    gd_TWA = np.array(TWA)\n",
    "    gd_EC = np.array(EC)\n",
    "    gd_PH_FIELD = np.array(PH_FIELD)\n",
    "    gd_O2 = np.array(O2)\n",
    "    gd_TURB = np.array(TURB)\n",
    "\n",
    "    # create gd_ZEIT\n",
    "    zeitli = []\n",
    "    for i in range(0,len(gd_SMPDATE)):\n",
    "        if len(gd_SMPTIME[i])>4:\n",
    "            dt = datetime(year = int(gd_SMPDATE[i][6:10]), month = int(gd_SMPDATE[i][3:5]), day = int(gd_SMPDATE[i][0:2]), hour = int(gd_SMPTIME[i][0:2]), minute = int(gd_SMPTIME[i][3:5]))\n",
    "        else:\n",
    "            dt = datetime(year = int(gd_SMPDATE[i][6:10]), month = int(gd_SMPDATE[i][3:5]), day = int(gd_SMPDATE[i][0:2]))\n",
    "        zeitli.append(dt)\n",
    "    gd_ZEIT = np.array(zeitli)\n",
    "\n",
    "    LogfileText = LogfileText+\"\\nAnzahl Zeilen im Geodin Export: \"+str(len(gd_LONGNAME))+\"\\n\"\n",
    "\n",
    "\n",
    "    ####### COPY xlsx aus der Vorlage\n",
    "\n",
    "    bearbZeitStr = str(datetime.today().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    shutil.copyfile(\"Vorlage_Bericht_NICHT-VERAENDERN/Vorlage_NICHT-VERAENDERN.xlsx\", \"Suedlink_WochenStatus_\"+bearbZeitStr+\".xlsx\")\n",
    "    #paBF.to_excel(\"SkriptOutput_\"+bearbZeitStr+\".xlsx\", index=False)\n",
    "\n",
    "\n",
    "    ###### df für export\n",
    "\n",
    "    Werteli = ['ab','wa','el','ph','o2']\n",
    "    Parameterli = ['min','min20','max80','max','mittel','anzahl','letzter','aktuell']\n",
    "\n",
    "    dfcolimp = ['id','zeit-aktuell']\n",
    "    for el1 in Werteli:\n",
    "        for el2 in Parameterli:\n",
    "            dfcolimp.append(el1+\"-\"+el2)\n",
    "    dfcolimp.append('tr-letzter')\n",
    "    dfcolimp.append('tr-aktuell')\n",
    "    dfcolimp.append('zeit-ersterDP')\n",
    "    dfcolimp.append('zeit-letzterDP')\n",
    "\n",
    "    df = pd.DataFrame(columns=dfcolimp)\n",
    "\n",
    "\n",
    "    ###### Import ILF-Wöchentlich\n",
    "\n",
    "    if len(os.listdir(\"ImportSkript/woechentlich-eigene\")) != 1:\n",
    "        LogfileText = LogfileText+\"\\nEs liegt nicht genau 1 Datei in ImportSkript/woechentlich-eigene\"\n",
    "\n",
    "    LogfileText = LogfileText+\"\\nFür den wöchentlichen Bericht der ILF-Messstellen wurde die Datei \\\"\"+os.listdir(\"ImportSkript/woechentlich-eigene\")[0]+\"\\\" verwendet\\n\"\n",
    "    egdf = pd.read_excel(\"ImportSkript/woechentlich-eigene/\"+os.listdir(\"ImportSkript/woechentlich-eigene\")[0])\n",
    "\n",
    "    for line in egdf[\"INVID\"]:\n",
    "        if \"_ds\" not in line:\n",
    "            #Zeit\n",
    "            smpdate = str(egdf[\"SMPDATE\"][np.where(egdf[\"INVID\"]==line)[0][0]])\n",
    "            smptime = str(egdf[\"SMPTIME\"][np.where(egdf[\"INVID\"]==line)[0][0]])\n",
    "            if smptime==\"nan\":\n",
    "                smptime = \"00:00\"\n",
    "            dt = datetime(year = int(smpdate[0:4]), month = int(smpdate[5:7]), day = int(smpdate[8:10]), hour = int(smptime[0:2]), minute = int(smptime[3:5]))\n",
    "            #5 Werte (Trübung fehlt noch)\n",
    "            A = egdf[\"A\"][np.where(egdf[\"INVID\"]==line)[0][0]]\n",
    "            WT = egdf[\"W_TEMP\"][np.where(egdf[\"INVID\"]==line)[0][0]]\n",
    "            EL = egdf[\"LF\"][np.where(egdf[\"INVID\"]==line)[0][0]]\n",
    "            PH = egdf[\"PHWERT\"][np.where(egdf[\"INVID\"]==line)[0][0]]\n",
    "            O2 = egdf[\"O2_FELD\"][np.where(egdf[\"INVID\"]==line)[0][0]]\n",
    "\n",
    "            newRow = {'id': [line], 'zeit-aktuell': [dt], 'ab-aktuell': [A], 'wa-aktuell': [WT], 'el-aktuell': [EL], 'ph-aktuell': [PH], 'o2-aktuell': [O2]}\n",
    "            newRow = pd.DataFrame(newRow)\n",
    "            df = pd.concat([df,newRow], ignore_index=True)\n",
    "\n",
    "    ###### Import 3te-Wöchentlich\n",
    "\n",
    "    if len(os.listdir(\"ImportSkript/woechentlich-dritte\")) != 1:\n",
    "        LogfileText = LogfileText+\"\\nEs liegt nicht genau 1 Datei in ImportSkript/woechentlich-dritte\"\n",
    "\n",
    "    LogfileText = LogfileText+\"\\nFür den wöchentlichen Bericht der Messstellen Dritter wurde die Datei \\\"\"+os.listdir(\"ImportSkript/woechentlich-dritte\")[0]+\"\\\" verwendet\\n\"\n",
    "    drdf = pd.read_excel(\"ImportSkript/woechentlich-dritte/\"+os.listdir(\"ImportSkript/woechentlich-dritte\")[0])\n",
    "\n",
    "    for line in drdf[\"INVID\"]:\n",
    "        if \"PA\" in line:\n",
    "            #Zeit\n",
    "            smpdate = str(drdf[\"SMPDATE\"][np.where(drdf[\"INVID\"]==line)[0][0]])\n",
    "            dt = datetime(year = int(smpdate[0:4]), month = int(smpdate[5:7]), day = int(smpdate[8:10]), hour = int(smpdate[11:13]), minute = int(smpdate[14:16]))\n",
    "            #5 Werte (Trübung fehlt noch)\n",
    "            A = drdf[\"WLV_COLLAR [m]\"][np.where(drdf[\"INVID\"]==line)[0][0]]\n",
    "            WT = drdf[\"WAT [°C]\"][np.where(drdf[\"INVID\"]==line)[0][0]]\n",
    "            EL = drdf[\"ELL [µS/cm]\"][np.where(drdf[\"INVID\"]==line)[0][0]]\n",
    "            PH = drdf[\"PH [–]\"][np.where(drdf[\"INVID\"]==line)[0][0]]\n",
    "            O2 = drdf[\"O2 [mg/l]\"][np.where(drdf[\"INVID\"]==line)[0][0]]\n",
    "\n",
    "            newRow = {'id': [line], 'zeit-aktuell': [dt], 'ab-aktuell': [A], 'wa-aktuell': [WT], 'el-aktuell': [EL], 'ph-aktuell': [PH], 'o2-aktuell': [O2]}\n",
    "            newRow = pd.DataFrame(newRow)\n",
    "            df = pd.concat([df,newRow], ignore_index=True)\n",
    "\n",
    "\n",
    "    ###### Füge die Daten der Statistik hinzu (aus dem automatischen geodin Export)\n",
    "\n",
    "    ArrayWerteLi = [gd_ABSTICH, gd_TWA, gd_EC, gd_PH_FIELD, gd_O2] #MUSS MIT REIHNFOLGE von Werteli (oben) übereinstimmen!!\n",
    "    #Werteli = ['ab','wa','el','ph','o2']\n",
    "    #Parameterli = ['min','min20','max80','max','mittel','anzahl','letzter','aktuell']\n",
    "\n",
    "    for ID in df[\"id\"]:\n",
    "        df.loc[df[\"id\"]==ID,\"zeit-ersterDP\"] = np.min(gd_ZEIT[np.where(gd_LONGNAME==ID)])\n",
    "        df.loc[df[\"id\"]==ID,\"zeit-letzterDP\"] = np.max(gd_ZEIT[np.where(gd_LONGNAME==ID)])\n",
    "\n",
    "        for i in range(0,len(ArrayWerteLi)):\n",
    "            arr = ArrayWerteLi[i]\n",
    "            WerteMitNan = arr[np.where(gd_LONGNAME==ID)]\n",
    "            Werte = WerteMitNan[np.where(np.isnan(WerteMitNan)==False)]\n",
    "            WerteZeit = gd_ZEIT[np.where(gd_LONGNAME==ID)]\n",
    "            WerteZeit = WerteZeit[np.where(np.isnan(WerteMitNan)==False)]\n",
    "\n",
    "            if len(Werte)>0:\n",
    "                df.loc[df[\"id\"]==ID, Werteli[i]+\"-min\"] = np.min(Werte)\n",
    "                df.loc[df[\"id\"]==ID, Werteli[i]+\"-max\"] = np.max(Werte)\n",
    "                df.loc[df[\"id\"]==ID, Werteli[i]+\"-mittel\"] = np.round(np.average(Werte),2)\n",
    "                n = len(Werte)\n",
    "                df.loc[df[\"id\"]==ID, Werteli[i]+\"-anzahl\"] = n\n",
    "                letzter = Werte[np.where(WerteZeit==np.max(WerteZeit))]\n",
    "                if len(letzter)==1:\n",
    "                    df.loc[df[\"id\"]==ID, Werteli[i]+\"-letzter\"] = letzter[0]\n",
    "                else:\n",
    "                    LogfileText = LogfileText+\"\\nFür \"+ID+\" gibt es zum Parameter \"+Werteli[i]+\" mehrere 'letzte' Werte (gleiches Datum)\\n\"\n",
    "\n",
    "                RemoveDP = int(n/5)\n",
    "                if RemoveDP > 0:\n",
    "                    WerteSortiert = np.sort(Werte)\n",
    "                    df.loc[df[\"id\"]==ID, Werteli[i]+\"-min20\"] = np.min(WerteSortiert[RemoveDP:])\n",
    "                    df.loc[df[\"id\"]==ID, Werteli[i]+\"-max80\"] = np.max(WerteSortiert[:-RemoveDP])\n",
    "                else:\n",
    "                    df.loc[df[\"id\"]==ID, Werteli[i]+\"-min20\"] = np.min(Werte)\n",
    "                    df.loc[df[\"id\"]==ID, Werteli[i]+\"-max80\"] = np.max(Werte)\n",
    "            else:\n",
    "                df.loc[df[\"id\"]==ID, Werteli[i]+\"-anzahl\"] = 0\n",
    "\n",
    "    df.to_excel('SkriptOutput_'+bearbZeitStr+'.xlsx', index=False)\n",
    "\n",
    "\n",
    "except:\n",
    "    LogfileText = LogfileText+\"\\nFehler im Ablauf des Skriptes. Vorgang nicht beendet.\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d1ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogfileText = LogfileText+\"\\nSkript finished: \"+bearbZeitStr\n",
    "with open(\"LogFile.txt\", \"w\") as file:\n",
    "    file.write(LogfileText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc133a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d6990b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e5c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1315458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070e399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c4c4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099c56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc96fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386102be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c63e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430740d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
